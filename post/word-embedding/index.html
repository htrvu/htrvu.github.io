<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Giá»›i thiá»‡u hai phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« phá»• biáº¿n lÃ  One-hot Encoding vÃ  Word Embedding (Skip-gram vÃ  CBoW)'>
<title>Word Embedding</title>

<link rel='canonical' href='https://htrvu.github.io/post/word-embedding/'>

<link rel="stylesheet" href="/scss/style.min.38e85664c6a3693af4a810d65ba9912a0751a4ee2f42b2ed7f83f842913e35c8.css"><meta property='og:title' content='Word Embedding'>
<meta property='og:description' content='Giá»›i thiá»‡u hai phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« phá»• biáº¿n lÃ  One-hot Encoding vÃ  Word Embedding (Skip-gram vÃ  CBoW)'>
<meta property='og:url' content='https://htrvu.github.io/post/word-embedding/'>
<meta property='og:site_name' content='Hoang Trong Vu'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='embedding' /><meta property='article:tag' content='one-hot-encoding' /><meta property='article:tag' content='word2vec' /><meta property='article:tag' content='skip-gram' /><meta property='article:tag' content='cbow' /><meta property='article:published_time' content='2023-02-19T10:51:57&#43;07:00'/><meta property='article:modified_time' content='2023-02-19T10:51:57&#43;07:00'/>
<meta name="twitter:title" content="Word Embedding">
<meta name="twitter:description" content="Giá»›i thiá»‡u hai phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« phá»• biáº¿n lÃ  One-hot Encoding vÃ  Word Embedding (Skip-gram vÃ  CBoW)">
    <link rel="shortcut icon" href="/neural.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu4ef57fa6d8ae56d86d9663ef18f7ace5_124758_300x0_resize_q75_box.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Hoang Trong Vu</a></h1>
            <h2 class="site-description">Keep going!</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/htrvu'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://www.linkedin.com/in/htrvu/'
                        target="_blank"
                        title="Linkedin"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"> <path stroke="none" d="M0 0h24v24H0z" fill="none"/> <rect x="4" y="4" width="16" height="16" rx="2" /> <line x1="8" y1="11" x2="8" y2="16" /> <line x1="8" y1="8" x2="8" y2="8.01" /> <line x1="12" y1="16" x2="12" y2="11" /> <path d="M16 16v-3a2 2 0 0 0 -4 0" /> </svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/about/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#one-hot-encoding">One-hot encoding</a>
      <ol>
        <li><a href="#Ã½-tÆ°á»Ÿng">Ã tÆ°á»Ÿng</a></li>
        <li><a href="#háº¡n-cháº¿-one-hot-encoding">Háº¡n cháº¿ one-hot encoding</a></li>
      </ol>
    </li>
    <li><a href="#word-embedding">Word Embedding</a>
      <ol>
        <li><a href="#Ã½-tÆ°á»Ÿng-1">Ã tÆ°á»Ÿng</a></li>
        <li><a href="#tÃ­nh-cháº¥t-cá»§a-word-embedding">TÃ­nh cháº¥t cá»§a Word Embedding</a></li>
        <li><a href="#sá»­-dá»¥ng-word-embedding-trong-rnn">Sá»­ dá»¥ng Word Embedding trong RNN</a></li>
        <li><a href="#há»c-word-embedding">Há»c Word Embedding</a>
          <ol>
            <li><a href="#embedding-matrix">Embedding matrix</a></li>
            <li><a href="#word2vec">Word2vec</a></li>
            <li><a href="#skip-gram">Skip-gram</a></li>
            <li><a href="#cbow-continuous-bag-of-words">CBoW (Continuous Bag of Words)</a></li>
            <li><a href="#trÃ­ch-xuáº¥t-embedding-matrix">TrÃ­ch xuáº¥t embedding matrix</a></li>
            <li><a href="#nháº­n-xÃ©t">Nháº­n xÃ©t</a></li>
          </ol>
        </li>
        <li><a href="#váº¥n-Ä‘á»-thiÃªn-vá»‹-trong-word-embdding">Váº¥n Ä‘á» thiÃªn vá»‹ trong Word Embdding</a></li>
      </ol>
    </li>
    <li><a href="#tÃ i-liá»‡u-tham-kháº£o">TÃ i liá»‡u tham kháº£o</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/nlp/" style="background-color: #2a9d8f; color: #fff;">
                Natual Language Processing
            </a>
        
            <a href="/categories/dl/" style="background-color: #2a9d8f; color: #fff;">
                Deep Learning
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/word-embedding/">Word Embedding</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Giá»›i thiá»‡u hai phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« phá»• biáº¿n lÃ  One-hot Encoding vÃ  Word Embedding (Skip-gram vÃ  CBoW)
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Feb 19, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    21 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>Trong bÃ i viáº¿t vá» RNN, mÃ¬nh Ä‘Ã£ Ä‘á» cáº­p khÃ¡ ká»¹ vá» mÃ´ hÃ¬nh nÃ y nhÆ°ng Ä‘á»ƒ á»©ng dá»¥ng Ä‘Æ°á»£c nÃ³ vÃ o cÃ¡c bÃ i toÃ¡n thÃ¬ ta cáº§n pháº£i lÃ m thÃªm bÆ°á»›c â€œsá»‘ hÃ³aâ€ dá»¯ liá»‡u tá»« vÄƒn báº£n sao cho mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c.</p>
<ul>
<li>Náº¿u mÃ¡y tÃ­nh hiá»ƒu Ä‘Æ°á»£c cÃ ng nhiá»u vá» cÃ¡c tá»« thÃ¬ nghÄ©a lÃ  cÃ¡ch sá»‘ hÃ³a cÃ ng cÃ³ hiá»‡u quáº£. Do Ä‘Ã³, ta cáº§n quan tÃ¢m Ä‘áº¿n váº¥n Ä‘á» â€œhiá»ƒuâ€. Hiá»ƒu nhÆ° tháº¿ nÃ o lÃ  Ä‘á»§ tá»‘t? ğŸ˜€</li>
</ul>
<p>Äá»‘i vá»›i NLP, ta cÃ³ nhá»¯ng phÆ°Æ¡ng phÃ¡p (hay cÃ³ thá»ƒ nÃ³i lÃ  ká»¹ thuáº­t) biá»ƒu diá»…n tá»« phá»• biáº¿n lÃ  <strong>one-hot encoding</strong>, <strong>TF-IDF</strong> vÃ  <strong>Word Embedding</strong>. Ná»™i dung cá»§a bÃ i viáº¿t nÃ y sáº½ táº­p trung vÃ o one-hot encoding vÃ  Word Embedding.</p>
<h2 id="one-hot-encoding">One-hot encoding</h2>
<h3 id="Ã½-tÆ°á»Ÿng">Ã tÆ°á»Ÿng</h3>
<p><strong>Tá»« Ä‘iá»ƒn (vocabulary)</strong> lÃ  má»™t thÃ nh pháº§n khÃ´ng thá»ƒ thiáº¿u cá»§a má»i há»‡ thá»‘ng ngÃ´n ngá»¯. Nhá»¯ng tá»« ta dÃ¹ng thÆ°á»ng ngÃ y háº§u nhÆ° lÃ  sáº½ náº±m á»Ÿ má»™t vá»‹ trÃ­ nÃ o Ä‘Ã³ trong tá»« Ä‘iá»ƒn (cÃ³ thá»ƒ cÃ¡c tá»« Ä‘á»‹a phÆ°Æ¡ng thÃ¬ sáº½ khÃ´ng cÃ³). One-hot encoding lÃ  phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n tá»« báº±ng chÃ­nh thÃ´ng tin vá»‹ trÃ­ nÃ y.</p>
<ul>
<li>Vá»›i nhá»¯ng tá»« khÃ´ng cÃ³ trong tá»« Ä‘iá»ƒn thÃ¬ ta thÆ°á»ng sá»­ dá»¥ng má»™t giÃ¡ trá»‹ vá»‹ trÃ­ Ä‘áº·c biá»‡t Ä‘á»ƒ cho biáº¿t tá»« Ä‘Ã³ lÃ  <strong>unknown</strong>.</li>
</ul>
<p>Giáº£ sá»­ táº­p tá»« Ä‘iá»ƒn cá»§a chÃºng ta cÃ³ $S$ tá»« vÃ  khÃ´ng cÃ³ tá»« trÃªn cÃ¡c vÄƒn báº£n lÃ  khÃ´ng cÃ³ trong tá»« Ä‘iá»ƒn. Khi Ä‘Ã³, má»—i tá»« sáº½ Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t <strong>vector nhá»‹ phÃ¢n</strong> cÃ³ $S$ chiá»u, vá»›i duy nháº¥t má»™t pháº§n tá»­ báº±ng 1 táº¡i chiá»u á»©ng vá»›i vá»‹ trÃ­ cá»§a tá»« Ä‘Ã³ trong tá»« Ä‘iá»ƒn vÃ  cÃ¡c pháº§n tá»­ cÃ²n láº¡i lÃ  0. VÃ­ dá»¥:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 230px;" src='./images/one-hot-encoding.png'>
<p align="center" style="margin: 0; color: #888;">Minh há»a phÆ°Æ¡ng phÃ¡p one-hot encoding vá»›i kÃ­ch thÆ°á»›c tá»« Ä‘iá»ƒn lÃ  9<br> Nguá»“n: <a href="https://www.shanelynn.ie/wp-content/uploads/2018/01/one-hot-word-embedding-vectors.png">Shane Lynn</a>
</p>
</div>
<p>Khi káº¿t há»£p phÆ°Æ¡ng phÃ¡p one-hot encoding vÃ o mÃ´ hÃ¬nh RNN Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n thÃ¬ á»Ÿ trong má»—i giai Ä‘oáº¡n ta sáº½ cÃ³:</p>
<ul>
<li>Input vÃ  label sáº½ lÃ  cÃ¡c vector nhá»‹ phÃ¢n tÆ°Æ¡ng á»©ng vá»›i cÃ¡c tá»«</li>
<li>Output lÃ  má»™t vector thá»ƒ hiá»‡n má»™t phÃ¢n bá»‘ xÃ¡c suáº¥t, vá»›i pháº§n tá»­ thá»© $i$ lÃ  xÃ¡c suáº¥t mÃ  tá»« output lÃ  tá»« á»Ÿ vá»‹ trÃ­ thá»© $i$ trong tá»« Ä‘iá»ƒn (do Ä‘Ã³ activation function thÆ°á»ng dÃ¹ng á»Ÿ Ä‘Ã¢y chÃ­nh lÃ  softmax)</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 400px;" src='./images/one-hot-with-rnn.png'>
<p align="center" style="margin: 0; color: #888;">VÃ­ dá»¥ Ã¡p dá»¥ng one-hot encoding vÃ o RNN trong bÃ i toÃ¡n sinh vÄƒn báº£n theo tá»«ng kÃ­ tá»±<br> Nguá»“n: <a href="https://slideplayer.com/slide/13124453">Stanford - Natural Language Processing</a>
</p>
</div>
<p><strong>VÃ¬ sao ta láº¡i sá»­ dá»¥ng vector nhá»‹ phÃ¢n Ä‘á»ƒ biá»ƒu diá»…n cÃ¡c tá»« mÃ  khÃ´ng dÃ¹ng luÃ´n giÃ¡ trá»‹ sá»‘ thá»±c lÃ  vá»‹ trÃ­ cá»§a tá»« trong tá»« Ä‘iá»ƒn?</strong></p>
<ul>
<li>CÃ¢u há»i nÃ y cÅ©ng giá»‘ng nhÆ° há»i ráº±ng trong bÃ i toÃ¡n image classification thÃ¬ vÃ¬ sao ta khÃ´ng cÃ i Ä‘áº·t output lÃ  má»™t sá»‘ thá»±c vÃ  sau Ä‘Ã³ lÃ m trÃ²n Ä‘á»ƒ cÃ³ káº¿t quáº£ mÃ  láº¡i lÃ  má»™t vector phÃ¢n bá»‘ xÃ¡c suáº¥t.</li>
<li>Táº¥t nhiÃªn lÃ  náº¿u lÃ m theo cÃ¡ch Ä‘Ã³ thÃ¬ má»i thá»© váº«n CÃ“ THá»‚ á»•n, quÃ¡ trÃ¬nh huáº¥n luyá»‡n cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c thÃ nh cÃ´ng. Tuy nhiÃªn, ta cÃ³ nhá»¯ng Ä‘iá»u cáº§n lÆ°u tÃ¢m nhÆ° sau:
<ul>
<li>Vá»›i output lÃ  sá»‘ thá»±c nhÆ° váº­y thÃ¬ cost function háº§u nhÆ° cháº¯c cháº¯n lÃ  <strong>MSE (Mean Square Error)</strong>. Khi Ä‘Ã³, quÃ¡ trÃ¬nh huáº¥n luyá»‡n sáº½ ráº¥t dá»… rÆ¡i vÃ o vá»‹ trÃ­ <strong>tá»‘i Æ°u cá»¥c bá»™</strong>.</li>
<li>Náº¿u mÃ  sá»‘ tá»« trong tá»« Ä‘iá»ƒn lÃ  ráº¥t nhiá»u thÃ¬ káº¿t quáº£ cá»§a cÃ¡c phÃ©p tÃ­nh trong cÃ¡ch biá»ƒu diá»…n dÃ¹ng sá»‘ thá»±c lÃ  ráº¥t lá»›n.</li>
<li>Äá»ƒ Ã½ ráº±ng, trong cÃ¡c biá»ƒu diá»…n one-hot encoding thÃ¬ khoáº£ng cÃ¡ch giá»¯a má»™t tá»« vá»›i cÃ¡c tá»« khÃ¡c nÃ³ sáº½ báº±ng háº±ng sá»‘ lÃ  $\sqrt{2}$. Trong khi Ä‘Ã³, vá»›i cÃ¡ch biá»ƒu diá»…n dÃ¹ng duy nháº¥t sá»‘ thá»±c thÃ¬ láº¡i khÃ´ng, cÃ³ nhá»¯ng cáº·p tá»« ráº¥t gáº§n nhau vÃ  cÃ³ nhá»¯ng cáº·p tá»« cá»±c kÃ¬ xa nhau, trong khi ta chÆ°a cÃ³ báº¥t cá»© Ä‘iá»u gÃ¬ thá»ƒ hiá»‡n Ä‘Æ°á»£c ráº±ng tá»« nÃ y nÃªn gáº§n vá»›i má»™t tá»« hÆ¡n so vá»›i tá»« kia.</li>
</ul>
</li>
</ul>
<h3 id="háº¡n-cháº¿-one-hot-encoding">Háº¡n cháº¿ one-hot encoding</h3>
<p>Trong cÃ¡ch biá»ƒu diá»…n one-hot encoding, ta tháº¥y ráº±ng mÃ¡y tÃ­nh Ä‘Ã£ cÃ³ thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c cÃ¡c tá»« vá»›i nhau, cÃ³ thá»ƒ biáº¿t Ä‘Æ°á»£c tá»« Ä‘Æ°á»£c dÃ¹ng trong cÃ¢u input lÃ  tá»« gÃ¬ vÃ  cÃ³ thá»ƒ cho biáº¿t tá»« mÃ  nÃ³ tÃ­nh ra Ä‘Æ°á»£c á»Ÿ output lÃ  tá»« gÃ¬. NÃ³i chung lÃ  mÃ¡y tÃ­nh Ä‘Ã£ hiá»ƒu Ä‘Æ°á»£c â€œmáº·t trÆ°á»›câ€ cá»§a cÃ¡c tá»«.</p>
<p>Tuy nhiÃªn, ta váº«n chÆ°a thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c <strong>má»‘i quan há»‡ giá»¯a cÃ¡c tá»« vá»›i nhau</strong>. NhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ pháº§n trÆ°á»›c, khoáº£ng cÃ¡ch giá»¯a hai cáº·p tá»« phÃ¢n biá»‡t báº¥t ká»³ Ä‘á»u báº±ng $\sqrt{2}$, trong khi nhá»¯ng tá»« cÃ³ nghÄ©a gáº§n gáº§n nhau nhÆ° â€œgoodâ€ vÃ  â€œniceâ€ thÃ¬ nÃªn cÃ³ khoáº£ng cÃ¡ch gáº§n nhau, cÃ²n nhá»¯ng tá»« trÃ¡i nghÄ©a nhau nhÆ° â€œgoodâ€ vÃ  â€œbadâ€ thÃ¬ cÅ©ng nÃªn cÃ¡ch nhau ráº¥t xa. ChÃ­nh vÃ¬ yáº¿u tá»‘ nÃ y mÃ  thÆ°á»ng thÃ¬ viá»‡c Ã¡p dá»¥ng one-hot encoding vÃ o RNN khÃ³ cÃ³ thá»ƒ mang láº¡i káº¿t quáº£ nhÆ° mong muá»‘n.</p>
<p>BÃªn cáº¡nh Ä‘Ã³, cÃ¡ch biá»ƒu diá»…n one-hot encoding tháº­t sá»± lÃ  ráº¥t tá»‘n kÃ©m vá» máº·t bá»™ nhá»› ğŸ˜€ Náº¿u mÃ  kÃ­ch thÆ°á»›c tá»« Ä‘iá»ƒn ráº¥t lá»›n thÃ¬ cá»© má»—i tá»« nhÆ° váº­y ta láº¡i cáº§n má»™t vector cÃ³ sá»‘ chiá»u khá»•ng lá»“ Ä‘á»ƒ biá»ƒu diá»…n. Má»™t cÃ¡ch kháº¯c phá»¥c váº¥n Ä‘á» nÃ y lÃ  sá»­ dá»¥ng <strong>ma tráº­n thÆ°a (sparse matrix)</strong>, nhÆ°ng mÃ  viá»‡c cÃ i Ä‘áº·t thÃ¬ cÅ©ng khÃ´ng pháº£i Ä‘Æ¡n giáº£n.</p>
<p>Tá»« cÃ¡c háº¡n cháº¿ cá»§a one-hot encoding, ta cÃ³ má»™t phÆ°Æ¡ng phÃ¡p tá»‘t hÆ¡n, vá»«a cÃ³ thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a cÃ¡c tá»« vÃ  vá»«a tiáº¿t kiá»‡m Ä‘Æ°á»£c bá»™ nhá»›, Ä‘Ã³ lÃ  <strong>Word Embedding</strong>!</p>
<h2 id="word-embedding">Word Embedding</h2>
<h3 id="Ã½-tÆ°á»Ÿng-1">Ã tÆ°á»Ÿng</h3>
<p>Äáº§u tiÃªn, <strong>embedding</strong> nÃ³i chung lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Æ°a má»™t vector cÃ³ sá»‘ chiá»u lá»›n (thÆ°á»ng á»Ÿ dáº¡ng thÆ°a, tá»©c lÃ  háº§u háº¿t cÃ¡c pháº§n tá»­ Ä‘á»u báº±ng 0), vá» má»™t vector cÃ³ sá»‘ chiá»u nhá» hÆ¡n (vÃ  khÃ´ng thÆ°a).</p>
<ul>
<li>Ta tháº¥y ngay ráº±ng one-hot vector Ä‘á»ƒ biá»ƒu diá»…n cÃ¡c tá»« trong má»™t táº­p tá»« Ä‘iá»ƒn lá»›n chÃ­nh lÃ  vector cÃ³ sá»‘ chiá»u lá»›n vÃ  á»Ÿ dáº¡ng thÆ°a ğŸ˜€</li>
<li>Embedding cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng á»Ÿ nhiá»u máº£ng khÃ¡c nhau chá»© khÃ´ng pháº£i má»—i xá»­ lÃ½ ngÃ´n ngá»¯, vÃ­ dá»¥ nhÆ° hÃ¬nh áº£nh cÅ©ng cÃ³.</li>
</ul>
<p><strong>Word Embedding</strong> lÃ  má»™t phÆ°Æ¡ng phÃ¡p biá»ƒu diá»…n cÃ¡c tá»« báº±ng má»™t <strong>vector Ä‘áº·c trÆ°ng</strong>. VÃ­ dá»¥, vá»›i cÃ¡c tá»« {man, woman, king, queen, apple, orange} vÃ  táº­p cÃ¡c Ä‘áº·c trÆ°ng {gender, age, food} thÃ¬ ta cÃ³ thá»ƒ biá»ƒu diá»…n má»—i tá»« báº±ng má»™t vector 3 chiá»u nhÆ° sau:</p>
<div class="table-wrapper"><table>
<thead>
<tr>
<th></th>
<th>man</th>
<th>woman</th>
<th>king</th>
<th>queen</th>
<th>apple</th>
<th>orange</th>
</tr>
</thead>
<tbody>
<tr>
<td>gender</td>
<td>-1</td>
<td>1</td>
<td>-0.9</td>
<td>0.97</td>
<td>0.0</td>
<td>0.01</td>
</tr>
<tr>
<td>age</td>
<td>0.3</td>
<td>0.25</td>
<td>0.7</td>
<td>0.69</td>
<td>0.02</td>
<td>0.0</td>
</tr>
<tr>
<td>food</td>
<td>0.01</td>
<td>0.0</td>
<td>0.005</td>
<td>0.015</td>
<td>0.97</td>
<td>0.96</td>
</tr>
</tbody>
</table></div>
<ul>
<li>Trong báº£ng trÃªn, má»—i tá»« trong tá»« Ä‘iá»ƒn ban Ä‘áº§u Ä‘Ã£ Ä‘Æ°á»£c Ã¡nh xáº¡ thÃ nh má»™t vector 3 chiá»u (cÃ²n one-hot vector Ä‘á»ƒ biá»ƒu diá»…n chÃºng thÃ¬ cÃ³ 6 chiá»u). Trong Ä‘Ã³, giÃ¡ trá»‹ vector á»©ng vá»›i má»—i tá»« sáº½ chá»©a nhá»¯ng nÃ©t <strong>Ä‘áº·c trÆ°ng vá» máº·t ngá»¯ nghÄ©a</strong> cá»§a tá»« Ä‘Ã³.</li>
<li>KÃ­ hiá»‡u $e_{word}$ lÃ  embedding vector cá»§a tá»« $word$. Ta cÃ³ má»™t sá»‘ nháº­n xÃ©t sau:
<ul>
<li>$e_{apple}$ vÃ  $e_{orange}$ cÃ³ giÃ¡ trá»‹ táº¡i Ä‘áº·c trÆ°ng food ráº¥t cao vÃ  hai Ä‘áº·c trÆ°ng cÃ²n láº¡i thÃ¬ khÃ´ng.</li>
<li>$e_{man}$ cÃ³ Ä‘áº·c trÆ°ng gender lÃ  -1 cÃ²n $e_{woman}$ lÃ  1, hÃ m Ã½ ráº±ng giá»›i tÃ­nh â€œmanâ€  vÃ  â€œwomanâ€ lÃ  trÃ¡i ngÆ°á»£c nhau.</li>
<li>$e_{man}$ vá»›i $e_{king}$ cÃ³ giÃ¡ trá»‹ táº¡i Ä‘áº·c trÆ°ng gender ráº¥t giá»‘ng nhau, Ä‘á»‘i vá»›i age thÃ¬ cÃ³ sá»± khÃ¡c biá»‡t, hÃ m Ã½ ráº±ng â€œkingâ€ thÃ¬ thÆ°á»ng lá»›n tuá»•i hÆ¡n â€œmanâ€. Ta cÃ³ nhÃ¢n xÃ©t tÆ°Æ¡ng tá»± vá»›i â€œwomanâ€ vÃ  â€œkingâ€.</li>
</ul>
</li>
<li>Náº¿u ta tÃ­nh thá»­ <strong>Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (similarity)</strong> giá»¯a cÃ¡c vector (thÆ°á»ng lÃ  <strong>khoáº£ng cÃ¡ch Cosine</strong> hoáº·c <strong>khoáº£ng cÃ¡ch Euclid</strong>), thÃ¬ káº¿t quáº£ sáº½ cÃ³ Ã½ nghÄ©a nhÆ° sau:
<ul>
<li>Hai vector $e_{man}$ vÃ  $e_{king}$ ráº¥t gáº§n nhau. TÆ°Æ¡ng tá»± vá»›i $e_{woman}$ vÃ  $e_{queen}$, $e_{apple}$ vÃ  $e_{orange}$. Äiá»u nÃ y thá»ƒ hiá»‡n ráº±ng cÃ¡c tá»« trong má»—i cáº·p cÃ³ quan há»‡ gáº§n gÅ©i vá»›i nhau vá» ngá»¯ nghÄ©a.</li>
<li>Hai vector $e_{man}$ vÃ  $e_{woman}$ cÃ³ hÆ°á»›ng gáº§n nhÆ° lÃ  ngÆ°á»£c nhau, thá»ƒ hiá»‡n ráº±ng hai tá»« nÃ y cÃ³ quan há»‡ trÃ¡i ngÆ°á»£c nhau.</li>
</ul>
</li>
</ul>
<p>ThÃ´ng thÆ°á»ng, ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p <strong>t-SNE</strong> Ä‘á»ƒ giáº£m chiá»u cÃ¡c embedding vector xuá»‘ng 2 chiá»u vÃ  trá»±c quan hÃ³a chÃºng Ä‘á»ƒ cÃ³ gÃ³c nhÃ¬n rÃµ hÆ¡n vá» Word Embedding. VÃ­ dá»¥ nhÆ° hÃ¬nh bÃªn dÆ°á»›i, vá»›i cÃ¡c tá»« cÃ³ nghÄ©a tÆ°Æ¡ng tá»± nhau thÃ¬ ta sáº½ tháº¥y chÃºng cÃ³ xu hÆ°á»›ng cÃ¹ng thuá»™c vá» má»™t cá»¥m:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 500px;" src='./images/word-embedding-visualization.png'>
<p align="center" style="margin: 0; color: #888;">Sá»­ dá»¥ng t-SNE Ä‘á»ƒ trá»±c quan hÃ³a cÃ¡c embedding vector<br>Nguá»“n: <a href="https://neptune.ai/blog/word-embeddings-guide](https://neptune.ai/blog/word-embeddings-guide">Neptune AI</a>
</p>
</div>
<p>Äá»‘i vá»›i trá»±c quan hÃ³a trong khÃ´ng gian 3 chiá»u thÃ¬ cÃ¡c báº¡n cÃ³ thá»ƒ truy cáº­p vÃ o trang <a class="link" href="https://projector.tensorflow.org/"  target="_blank" rel="noopener"
    >nÃ y</a> cá»§a Tensorflow. Trong trang web Ä‘Ã³, náº¿u tÃ¬m kiáº¿m tá»« â€œsoccerâ€ thÃ¬ ta sáº½ tháº¥y cÃ¡c vector Ä‘Æ°á»£c highlight lÃªn lÃ  vector á»©ng vá»›i cÃ¡c tá»« cÃ³ nghÄ©a ráº¥t tÆ°Æ¡ng tá»±, vÃ  háº§u háº¿t lÃ  liÃªn quan Ä‘áº¿n thá»ƒ thao.</p>
<p style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 480px;" src='./images/tf-embedding-ex.png'>
</p>
<p>NhÆ° váº­y, phÆ°Æ¡ng phÃ¡p Word Embedding Ä‘Ã£ cÃ³ thá»ƒ kháº¯c phá»¥c Ä‘Æ°á»£c háº¡n cháº¿ cá»§a one-hot encoding trong viá»‡c thá»ƒ hiá»‡n <strong>má»‘i quan há»‡ giá»¯a cÃ¡c tá»«</strong>.</p>
<h3 id="tÃ­nh-cháº¥t-cá»§a-word-embedding">TÃ­nh cháº¥t cá»§a Word Embedding</h3>
<p>Trong kháº£ nÄƒng biá»ƒu diá»…n cÃ¡c tá»« báº±ng vector Ä‘áº·c trÆ°ng vÃ  thá»ƒ hiá»‡n Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a tá»« Ä‘Ã³ vá»›i nhá»¯ng tá»« khÃ¡c, ta cÃ³ má»™t tÃ­nh cháº¥t thÃº vá»‹ liÃªn quan Ä‘áº¿n <strong>Analogy Reasoning (suy diá»…n tÆ°Æ¡ng tá»±)</strong>.</p>
<ul>
<li>VÃ­ dá»¥: Cho trÆ°á»›c 3 tá»« â€œmanâ€, â€œwomanâ€ vÃ  â€œkingâ€. Trong Ä‘Ã³, â€œmanâ€ Ä‘Ã£ cÃ³ má»™t quan há»‡ nháº¥t Ä‘á»‹nh vá»›i â€œwomanâ€. Ta cáº§n tÃ¬m má»™t tá»« sao cho quan há»‡ giá»¯a â€œkingâ€ vá»›i tá»« nÃ y cÅ©ng tÆ°Æ¡ng tá»± nhÆ° quan há»‡ giá»¯a â€œmanâ€ vÃ  â€œwomanâ€.</li>
</ul>
<p>Náº¿u má»™t há»‡ thá»‘ng Word Embedding <strong>Ä‘á»§ tá»‘t</strong> thÃ¬ ta sáº½ cÃ³ tÃ­nh cháº¥t ráº±ng nhá»¯ng cáº·p tá»« $(w_{i1}, w_{i2})$ mÃ  cÃ³ quan há»‡ giá»¯a hai tá»« trong má»™t cáº·p lÃ  ráº¥t tÆ°Æ¡ng tá»± nhau thÃ¬ cÃ¡c vector $x_i = e_{w_{i1}} - e_{w_{i2}}$ sáº½ cÃ³ hÆ°á»›ng cÅ©ng ráº¥t tÆ°Æ¡ng tá»±. VÃ­ dá»¥:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 300px;" src='./images/analogy-reasoning.png'>
<p align="center" style="margin: 0; color: #888;">Minh há»a Analogy Reasoning<br>Nguá»“n: <a href="https://polakowo.io/datadocs/assets/1*jpnKO5X0Ii8PVdQYFO2z1Q.png">Polakowo</a>
</p>
</div>
<p>Dá»±a vÃ o tÃ­nh cháº¥t nÃ y, ta cÃ³ thá»ƒ giáº£i quyáº¿t cÃ¢u há»i Ä‘áº·t ra á»Ÿ phÃ­a trÃªn ráº±ng tá»« cáº§n tÃ¬m sáº½ lÃ  â€œqueenâ€. Äá»ƒ kiá»ƒm chá»©ng, hÃ£y xÃ©t láº¡i báº£ng á»Ÿ pháº§n <strong>2.1</strong>, ta cÃ³:</p>
<ul>
<li>$e_{man} -e_{woman} = \begin{bmatrix}-2 &amp; 0.05 &amp; 0.01\end{bmatrix}^\top$</li>
<li>$e_{king} - e_{queen} =  \begin{bmatrix}-1.87 &amp; 0.01 &amp; -0.01 \end{bmatrix}^\top$</li>
</ul>
<p>Äá»ƒ biá»ƒu diá»…n bÃ i toÃ¡n analogy reasoning nhÆ° vÃ­ dá»¥ bÃªn trÃªn má»™t cÃ¡ch hÃ¬nh thá»©c hÆ¡n, ta cÃ³ thá»ƒ phÃ¡t biá»ƒu nhÆ° sau:</p>
<ul>
<li>
<p>TÃ¬m tá»« $w$ sao cho</p>
<p>$$w = \argmax_w \left (  \text{sim} ( e_w, e_{man} - e_{woman} + e_{king} )\right )$$</p>
</li>
</ul>
<p>vÃ  káº¿t quáº£ lÃ  $w = queen$.</p>
<h3 id="sá»­-dá»¥ng-word-embedding-trong-rnn">Sá»­ dá»¥ng Word Embedding trong RNN</h3>
<p>Trong phÆ°Æ¡ng phÃ¡p one-hot encoding, ta sá»­ dá»¥ng cÃ¡c one-hot vector á»Ÿ input vÃ  output cá»§a RNN. Äá»‘i vá»›i word-embedding thÃ¬ ta sáº½ thay Ä‘á»•i má»™t chÃºt á»Ÿ input, cÃ²n output thÃ¬ váº«n dÃ¹ng one-hot encoding Ä‘á»ƒ biáº¿t Ä‘Æ°á»£c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»« nÃ o. ğŸ˜œ</p>
<p><strong>Táº¡i sao láº¡i nhÆ° tháº¿?</strong></p>
<ul>
<li>Äá»‘i vá»›i input, Ä‘Æ°a vÃ o RNN embedding vector thÃ¬ cháº¯c cháº¯n mÃ´ hÃ¬nh cÃ³ thá»ƒ há»c tá»‘t hÆ¡n so vá»›i one-hot vector rá»“i.</li>
<li>Trong output, ta tháº¥y ráº±ng viá»‡c mÃ´ hÃ¬nh tÃ­nh ra má»™t vector dáº¡ng phÃ¢n bá»‘ xÃ¡c suáº¥t vÃ  sau Ä‘Ã³ xÃ¡c Ä‘á»‹nh tá»« tÆ°Æ¡ng á»©ng báº±ng cÃ¡ch softmax thÃ¬ sáº½ dá»… hÆ¡n nhiá»u so vá»›i viá»‡c output ra má»™t embedding vector rá»“i tá»« vector nÃ y Ä‘i tÃ¬m tá»« gá»‘c. Tháº­t ra thÃ¬ mÃ¬nh chÆ°a tháº¥y ai thá»±c hiá»‡n tÃ¬m tá»« dá»±a vÃ o embedding vector cáº£. ğŸ˜€</li>
</ul>
<p>NhÆ° váº­y, Ä‘á»ƒ sá»­ dá»¥ng Word Embedding trong RNN thÃ¬ ta sáº½ dÃ¹ng embedding vector cá»§a cÃ¡c tá»« Ä‘á»ƒ lÃ m input cho RNN.</p>
<ul>
<li>VÃ­ dá»¥: mÆ°á»£n táº¡m áº£nh cá»§a cÃ¡c phÃ¡p sÆ° Trung Hoa z =))
word-embedding-with-rnn.png</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 400px;" src='./images/word-embedding-with-rnn.png'>
<p align="center" style="margin: 0; color: #888;">Minh há»a sá»­ dá»¥ng Word Embedding trong RNN<br>Nguá»“n: <a href="https://d1dwq032kyr03c.cloudfront.net/upload/images/20210920/20140426lkFvCOLUFZ.png">PhÃ¡p sÆ° nÃ o Ä‘Ã³</a>
</p>
</div>
<p><strong>LÆ°u Ã½.</strong></p>
<ul>
<li>Khi sá»­ dá»¥ng Word Embedding trong RNN thÃ¬ thÆ°á»ng ta sáº½ dÃ¹ng theo hÆ°á»›ng <strong>transfer learning</strong> hoáº·c <strong>fine-tuning</strong>. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c embedding vector cá»§a má»—i tá»« cÃ³ thá»ƒ Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p sáºµn, ta chá»‰ viá»‡c Ä‘em vÃ o dÃ¹ng trong mÃ´ hÃ¬nh lÃ  Ä‘á»§ vÃ  náº¿u cáº§n thiáº¿t thÃ¬ cÅ©ng sáº½ tiáº¿p tá»¥c huáº¥n luyá»‡n trÃªn ná»n táº£ng Ä‘Ã£ cÃ³.</li>
</ul>
<h3 id="há»c-word-embedding">Há»c Word Embedding</h3>
<h4 id="embedding-matrix">Embedding matrix</h4>
<p>á» cÃ¡c pháº§n trÃªn thÃ¬ ta chá»‰ má»›i nÃªu sÆ¡ lÆ°á»£c vá» phÆ°Æ¡ng phÃ¡p Word Embedding chá»© chÆ°a Ä‘á» cáº­p Ä‘áº¿n viá»‡c lÃ m tháº¿ nÃ o Ä‘á»ƒ xÃ¢y dá»±ng Ä‘Æ°á»£c cÃ¡c vector biá»ƒu diá»…n tá»« nhÆ° váº­y. Äáº§u tiÃªn, thá»© chÃºng ta cáº§n xÃ¢y dá»±ng trong Word Embedding Ä‘Æ°á»£c gá»i lÃ  <strong>embedding matrix</strong> (kÃ­ hiá»‡u lÃ  $E$), vá»›i sá»‘ dÃ²ng lÃ  sá»‘ Ä‘áº·c trÆ°ng Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ mÃ´ táº£ cho má»—i tá»« vÃ  sá»‘ cá»™t báº±ng vá»›i sá»‘ tá»« trong tá»« Ä‘iá»ƒn.</p>
<ul>
<li>
<p>Äá»ƒ minh há»a, ta sáº½ dÃ¹ng láº¡i vÃ­ dá»¥ á»Ÿ pháº§n <strong>2.1.</strong> embedding matrix $E$ sáº½ lÃ </p>
<p>$$
E = \begin{bmatrix}-1 &amp; 1 &amp; -0.9Â  &amp; 0.97Â  &amp; 0.0Â  &amp; 0.01 \\Â 0.3Â  &amp; 0.25Â  &amp; 0.7 &amp; 0.69 &amp; 0.02 &amp; 0.0Â \\Â 0.01 &amp; 0.0 &amp; 0.005 &amp; 0.015 &amp; 0.97 &amp; 0.96\end{bmatrix}
$$</p>
</li>
<li>
<p>Vá»›i tá»« $man$, one-hot vector cá»§a tá»« nÃ y lÃ </p>
<p>$$o_{man} = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\end{bmatrix}^\top$$</p>
</li>
<li>
<p>Embedding vector cá»§a $man$ sáº½ Ä‘Æ°á»£c tÃ­nh báº±ng cÃ´ng thá»©c</p>
<p>$$e_{man} = E \cdot o_{man} = \begin{bmatrix} -1 &amp; 0.3 &amp; 0.01 \end{bmatrix}^\top$$</p>
</li>
</ul>
<p>Äá»ƒ xÃ¢y dá»±ng cÃ¡c embedding matrix, ta cÃ³ hai hÆ°á»›ng phá»• biáº¿n nhÆ° sau:</p>
<ol>
<li><strong>Word2vec:</strong> Huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh MLP. embedding matrix sáº½ lÃ  má»™t ma tráº­n trá»ng sá»‘ trong mÃ´ hÃ¬nh MLP sau khi Ä‘Ã£ huáº¥n luyá»‡n xong.</li>
<li><strong>GloVe</strong> (Global Vector for word representations): Máº¡nh hÆ¡n Word2vec, cÃ³ sá»­ dá»¥ng thÃªm nhá»¯ng ká»¹ thuáº­t liÃªn quan Ä‘áº¿n xÃ¡c suáº¥t thá»‘ng kÃª.</li>
</ol>
<p>Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ táº­p trung vÃ o word2vec.</p>
<h4 id="word2vec">Word2vec</h4>
<p>Word2vec lÃ  má»™t mÃ´ hÃ¬nh ráº¥t Ä‘Æ¡n giáº£n vÃ  ná»•i tiáº¿ng trong viá»‡c táº¡o embedding matrix. Ã tÆ°á»Ÿng cá»§a word2vec xuáº¥t phÃ¡t tá»« hai nháº­n xÃ©t sau:</p>
<ul>
<li>Hai tá»« thÆ°á»ng xuáº¥t hiá»‡n trong cÃ¡c ngá»¯ cáº£nh tÆ°Æ¡ng tá»± nhau thÃ¬ cÃ³ thá»ƒ cÃ³ quan há»‡ gáº§n gÅ©i nhau vá» máº·t ngá»¯ nghÄ©a.</li>
<li>Khi cho biáº¿t trÆ°á»›c cÃ¡c tá»« xung quanh tá»« bá»‹ thiáº¿u trong cÃ¢u, ta cÃ³ thá»ƒ dá»± Ä‘oÃ¡n ra Ä‘Æ°á»£c tá»« Ä‘Ã³. VÃ­ dá»¥, vá»›i cÃ¢u â€œHusky lÃ  má»™t â€¦ chÃ³ ráº¥t ngÃ¡oâ€ thÃ¬ tá»« trong dáº¥u ba cháº¥m cÃ³ kháº£ nÄƒng cao lÃ  â€œloÃ iâ€. ÄÃ¢y lÃ  vÃ­ dá»¥ vá»›i cÃ¢u ngáº¯n, cÃ²n náº¿u cÃ¢u dÃ i thÃ¬ Ä‘Ã´i khi ta chá»‰ cáº§n xÃ©t táº§m 10 tá»« xung quanh tá»« cáº§n dá»± Ä‘oÃ¡n lÃ  Ä‘Ã£ Ä‘á»§ Ä‘á»ƒ Ä‘oÃ¡n ra Ä‘Æ°á»£c.</li>
</ul>
<p>Äáº§u tiÃªn, ta Ä‘á» cáº­p Ä‘áº¿n khÃ¡i niá»‡m <strong>tá»« má»¥c tiÃªu (target word)</strong> vÃ  <strong>tá»« ngá»¯ cáº£nh (context word).</strong> CÃ³ thá»ƒ nÃ³i tá»« má»¥c tiÃªu lÃ  tá»« ta Ä‘ang xem xÃ©t vÃ  tá»« ngá»¯ cáº£nh lÃ  cÃ¡c tá»« xuáº¥t hiá»‡n xung quanh tá»« má»¥c tiÃªu á»Ÿ trong cÃ¡c Ä‘oáº¡n vÄƒn báº£n cá»§a kho dá»¯ liá»‡u, vá»›i pháº¡m vi lÃ  cÃ¡ch tá»« má»¥c tiÃªu khÃ´ng quÃ¡ $\dfrac{C}{2}$ tá»«. VÃ¹ng pháº¡m vi nÃ y cÃ²n láº¡i lÃ  <strong>cá»­a sá»• trÆ°á»£t (sliding window)</strong>.</p>
<ul>
<li>Vá»›i cÃ¢u vÃ­ dá»¥ á»Ÿ trÃªn thÃ¬, tá»« â€œloÃ iâ€ lÃ  target word. Náº¿u xÃ©t cá»­a sá»• trÆ°á»£t cÃ³ kÃ­ch thÆ°á»›c $C = 4$ thÃ¬ cÃ¡c context word sáº½ bao gá»“m â€œlÃ â€, â€œmá»™tâ€, â€œchÃ³â€, â€œráº¥tâ€.</li>
<li>Äá»ƒ cÃ³ cÃ¡i nhÃ¬n rÃµ hÆ¡n vá» cÃ¡c khÃ¡i niá»‡m nÃ y, ta xÃ©t vÃ­ dá»¥ bÃªn dÆ°á»›i vá»›i kÃ­ch thÆ°á»›c sliding window lÃ  4.</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 380px;" src='./images/context-target-word.png'>
<p align="center" style="margin: 0; color: #888;">Tá»« mÃ u xanh lÃ  target word, cÃ¡c tá»« trong Ã´ mÃ u tráº¯ng lÃ  context word<br>Nguá»“n: <a href="https://machinelearningcoban.com/tabml_book/_images/word2vec_training_data.png">Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng</a>
</p>
</div>
<p><strong>LÆ°u Ã½.</strong></p>
<ul>
<li>Tá»« phÆ°Æ¡ng phÃ¡p word2vec, ta sáº½ cÃ³ <strong>hai embedding vector cho má»—i tá»«</strong>, á»©ng vá»›i hai trÆ°á»ng há»£p lÃ  tá»« Ä‘Ã³ Ä‘Ã³ng vai trÃ² target word vÃ  context word. LÃ½ do lÃ  vÃ­ trong má»—i tÃ¬nh huá»‘ng thÃ¬ ngá»¯ nghÄ©a cá»§a nÃ³ cÃ³ thá»ƒ sáº½ khÃ¡c nhau.</li>
</ul>
<p>Trong word2vec, ta sáº½ Ä‘i xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh <strong>MLP (Multi-layer Perceptron</strong>, hay nÃ³i cÃ¡ch khÃ¡c lÃ  Neural Network) chá»‰ gá»“m <strong>1 hidden layer</strong>, vá»›i má»¥c Ä‘Ã­ch cÃ³ thá»ƒ lÃ :</p>
<ol>
<li>Dá»±a vÃ o target word Ä‘á»ƒ dá»± Ä‘oÃ¡n context word</li>
<li>Dá»±a vÃ o cÃ¡c context word Ä‘á»ƒ dá»± Ä‘oÃ¡n target word</li>
</ol>
<p>TÃ¹y vÃ o má»¥c Ä‘Ã­ch mÃ  ta sáº½ cÃ³ má»™t kiáº¿n trÃºc MLP khÃ¡c nhau. Vá»›i má»¥c Ä‘Ã­ch (1) thÃ¬ ta cÃ³ S<strong>kip-gram</strong>, má»¥c Ä‘Ã­ch (2) lÃ  <strong>CBoW (Continuous Bag of Word)</strong></p>
<p>Quay láº¡i vá»›i hai nháº­n xÃ©t Ä‘Ã£ má»Ÿ ra Ã½ tÆ°á»Ÿng cho word2vec thÃ¬ nháº­n xÃ©t thá»© nháº¥t Ä‘Æ°á»£c thá»ƒ hiá»‡n rÃµ hÆ¡n á»Ÿ trong Skip-gram vÃ  nháº­n xÃ©t thá»© hai thÃ¬ á»Ÿ trong CBoW ğŸ˜€ Äá»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» sá»± khÃ¡c biá»‡t giá»¯a Skip-gram vÃ  CBoW, ta cÃ³ hÃ¬nh áº£nh so sÃ¡nh nhÆ° bÃªn dÆ°á»›i:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 300px;" src='./images/skip-gram-vs-cbow.png'>
<p align="center" style="margin: 0; color: #888;">Sá»± khÃ¡c biá»‡t giá»¯a CBoW vÃ  skip-gram trong má»™t cÃ¢u vá»›i target word lÃ  W(t), context word lÃ  W(t-2), W(t-1), W(t+1), W(t+2)<br>Nguá»“n: <a href="https://i.stack.imgur.com/ShJJX.png">https://i.stack.imgur.com/ShJJX.png</a>
</p>
</div>
<h4 id="skip-gram">Skip-gram</h4>
<p><strong>Skip-gram</strong> lÃ  cÃ¡ch xÃ¢y dá»±ng mÃ´ hÃ¬nh MLP theo hÆ°á»›ng dá»± Ä‘oÃ¡n context word dá»±a vÃ o target word. Vá» máº·t toÃ¡n há»c thÃ¬ ta sáº½ Ä‘i tÃ¬m xÃ¡c suáº¥t xáº£y ra cÃ¡c context word khi biáº¿t trÆ°á»›c target word.</p>
<ul>
<li>
<p>VÃ­ dá»¥, kho dá»¯ liá»‡u ta cÃ³ hai cÃ¢u lÃ  {â€œem áº¥y há»c toÃ¡n tá»‘tâ€, â€œem áº¥y há»c toÃ¡n giá»iâ€}. Vá»›i tá»« má»¥c tiÃªu â€œhá»câ€ vÃ  kÃ­ch thÆ°á»›c sliding window lÃ  $C=4$, ta sáº½ tÃ¬m xÃ¡c suáº¥t</p>
<p>$$ P_0 = P(\text{&ldquo;em&rdquo;}, \text{&ldquo;áº¥y&rdquo;}, \text{&ldquo;toÃ¡n&rdquo;}, \text{&ldquo;tá»‘t&rdquo;}, \text{&ldquo;giá»i&rdquo;} | \text{&ldquo;há»c&rdquo;}) $$</p>
<p>Giáº£ sá»­ cÃ¡c tá»« trÃªn lÃ  Ä‘á»™c láº­p vá»›i nhau, khi Ä‘Ã³</p>
<p>$$ P_0 = P(\text{&ldquo;em&rdquo;} | \text{&ldquo;há»c&rdquo;}) \cdot P(\text{&ldquo;áº¥y&rdquo;} | \text{&ldquo;há»c&rdquo;}) \cdot P(\text{&ldquo;toÃ¡n&rdquo;} | \text{&ldquo;há»c&rdquo;}) \cdot P(\text{&ldquo;tá»‘t&rdquo;} | \text{&ldquo;há»c&rdquo;}) \cdot P(\text{&ldquo;giá»i&rdquo;} | \text{&ldquo;há»c&rdquo;}) $$</p>
</li>
<li>
<p>Táº­p tá»« Ä‘iá»ƒn sáº½ cÃ³ 6 tá»« nÃªn input cá»§a mÃ´ hÃ¬nh MLP sáº½ lÃ  vector 6 chiá»u. Ta sá»­ dá»¥ng hidden layer vá»›i 300 neuron. XÃ©t hai cáº·p (context, target) láº§n lÆ°á»£t lÃ  (há»c, tá»‘t) vÃ  (há»c, giá»i). Khi Ä‘Ã³, mÃ´ hÃ¬nh skip-gram sáº½ cÃ³ dáº¡ng nhÆ° hÃ¬nh bÃªn dÆ°á»›i, vá»›i $\bold{U}$ vÃ  $\bold{V}$ láº§n lÆ°á»£t lÃ  ma tráº­n trá»ng sá»‘ giá»¯a layer input-hidden vÃ  hidden-output.</p>
</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 400px;" src='./images/skip-gram.png'>
<p align="center" style="margin: 0; color: #888;">Tham kháº£o: <a href="https://www.youtube.com/watch?v=akRbuXokLSo">ProtonX - Word2vec</a>
</p>
</div>
<ul>
<li>Ta tháº¥y ráº±ng, hai tá»« â€œtá»‘tâ€ vÃ  â€œgiá»iâ€ cÃ¹ng xuáº¥t hiá»‡n trong má»™t ngá»¯ cáº£nh, do Ä‘Ã³ chÃºng nÃªn cÃ³ quan há»‡ nÃ o Ä‘Ã³ vá» máº·t ngá»¯ nghÄ©a ğŸ˜€</li>
</ul>
<p><strong>LÆ°u Ã½.</strong></p>
<ul>
<li>Shape cá»§a $\bold{U}$ cÃ³ thá»ƒ lÃ  (embedding_dim x vocab_size), tá»©c lÃ  $(300 \times 6)$, hoáº·c lÃ  (vocab_size x embedding_dim), tá»©c lÃ  $(6 \times 300)$. Vá»›i bÃ i viáº¿t nÃ y thÃ¬ mÃ¬nh sá»­ dá»¥ng (embedding_dim x vocab_size). TÆ°Æ¡ng tá»± nhÆ° vá»›i $\bold{V}$.</li>
</ul>
<p>Khi láº§n Ä‘áº§u tÃ¬m hiá»ƒu vá» Skip-gram, mÃ¬nh cÃ³ má»™t tháº¯c máº¯c mÃ  mÃ¬nh nghÄ© lÃ  cÅ©ng ráº¥t nhiá»u ngÆ°á»i cÃ³ cÃ¹ng tháº¯c máº¯c nhÆ° tháº¿ ğŸ˜œ Trong hÃ¬nh trÃªn, ta tháº¥y ráº±ng mÃ´ hÃ¬nh cÃ¹ng nháº­n vÃ o má»™t input lÃ  one-hot vector cá»§a tá»« há»c, sá»­ dá»¥ng cÃ¹ng hai ma tráº­n trá»ng sá»‘ $\bold{U}$ vÃ  $\bold{V}$, vÃ¬ sao label láº¡i cÃ³ nhá»¯ng giÃ¡ trá»‹ khÃ¡c nhau?</p>
<ul>
<li>Thá»±c cháº¥t, trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n skip-gram, ta sáº½ sá»­ dá»¥ng optimizer <strong>SGD (stochastic gradient descent)</strong>, táº¡i má»—i thá»i Ä‘iá»ƒm thÃ¬ ta sáº½ <strong>chá»n ngáº«u nhiÃªn</strong> má»™t cáº·p (target, context) rá»“i tiáº¿n hÃ nh cáº­p nháº­t cÃ¡c ma tráº­n trá»ng sá»‘ má»™t chÃºt dá»±a theo cáº·p Ä‘Æ°á»£c chá»n. Trong Ä‘Ã³, phÃ©p chá»n nÃ y <strong>khÃ´ng nÃªn tuÃ¢n theo phÃ¢n phá»‘i Ä‘á»u</strong> mÃ  nÃªn cÃ³ heuristic má»™t chÃºt, vÃ­ dá»¥ nhÆ° cáº·p nÃ o xuáº¥t hiá»‡n cÃ ng nhiá»u thÃ¬ cÃ³ xÃ¡c suáº¥t Ä‘Æ°á»£c chá»n cÃ ng cao. Do Ä‘Ã³, cáº·p (target, context) nÃ o xuáº¥t hiá»‡n cÃ ng nhiá»u thÃ¬ mÃ´ hÃ¬nh cÃ ng â€œhá»câ€ Ä‘Æ°á»£c nhiá»u thá»© vá» nÃ³.</li>
<li>Káº¿t quáº£ lÃ  sau quÃ¡ trÃ¬nh huáº¥n luyá»‡n, tá»« dá»± Ä‘oÃ¡n cá»§a má»™t context word sáº½ lÃ  má»™t phÃ¢n bá»‘ xÃ¡c suáº¥t â€œÄ‘á»§ gáº§nâ€ vá»›i táº¥t cáº£ cÃ¡c target word cá»§a nÃ³ trong kho dá»¯ liá»‡u.</li>
</ul>
<p>NgoÃ i ra, trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n skip-gram thÃ¬ chÃºng ta thÆ°á»ng sá»­ dá»¥ng loss function lÃ  <strong>cross-entropy</strong> (cÃ³ dÃ¹ng Ä‘áº¿n $\text{softmax}$ activation function).</p>
<h4 id="cbow-continuous-bag-of-words">CBoW (Continuous Bag of Words)</h4>
<p>CÃ³ thá»ƒ nÃ³i <strong>CBoW</strong> lÃ  má»™t phiÃªn báº£n ngÆ°á»£c láº¡i cá»§a Skip-gram. Trong CBoW, ta sáº½ sá»­ dá»¥ng cÃ¡c context word Ä‘á»ƒ dá»± Ä‘oÃ¡n target word. Vá» máº·t toÃ¡n há»c thÃ¬ ta sáº½ Ä‘i tÃ¬m xÃ¡c suáº¥t xáº£y ra target word khi biáº¿t trÆ°á»›c cÃ¡c context word.</p>
<ul>
<li>Vá»›i cÃ¹ng vÃ­ dá»¥ nhÆ° pháº§n vá» Skip-gram, ta sáº½ tÃ¬m xÃ¡c suáº¥t</li>
</ul>
<p>$$P_0 = P(\text{&ldquo;há»c&rdquo;} | \text{&ldquo;em&rdquo;}, \text{&ldquo;áº¥y&rdquo;}, \text{&ldquo;toÃ¡n&rdquo;}, \text{&ldquo;tá»‘t&rdquo;}, \text{&ldquo;giá»i&rdquo;})$$</p>
<ul>
<li>LÃºc nÃ y, ta thÆ°á»ng tÃ­nh má»™t â€œtá»« trung bÃ¬nhâ€ cá»§a cÃ¡c context word (embedding vector trung bÃ¬nh), sau Ä‘Ã³ thay vÃ o biá»ƒu thá»©c trÃªn</li>
</ul>
<p>$$P_0 = P(\text{&ldquo;há»c&rdquo;} | \overline{word})$$</p>
<ul>
<li>Äá»ƒ dá»… mÃ¬nh há»a, ta xÃ©t hai context words â€œemâ€, â€œtoÃ¡nâ€ cá»§a target word â€œhá»câ€. Khi Ä‘Ã³, mÃ´ hÃ¬nh CBoW sáº½ cÃ³ dáº¡ng nhÆ° hÃ¬nh bÃªn dÆ°á»›i, vá»›i $\bold{V}$ vÃ  $\bold{U}$ lÃ  ma tráº­n trá»ng sá»‘ giá»¯a layer input-hidden vÃ  hidden-output. LÆ°u Ã½ ráº±ng, sau khi tÃ­nh ra output táº¡i hidden layer cá»§a cÃ¡c context word thÃ¬ ta sáº½ thá»±c hiá»‡n thao tÃ¡c <strong>tÃ­nh trung bÃ¬nh</strong> Ä‘á»ƒ cÃ³ má»™t vector trung bÃ¬nh, sau Ä‘Ã³ má»›i tÃ­nh ra predicted word.</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 350px;" src='./images/cbow.png'>
<p align="center" style="margin: 0; color: #888;">Tham kháº£o: <a href="https://www.youtube.com/watch?v=akRbuXokLSo">ProtonX - Word2vec</a>
</p>
</div>
<p>Trong huáº¥n luyá»‡n mÃ´ hÃ¬nh, ta cÅ©ng loss function lÃ  <strong>cross-entropy</strong> vÃ  optimizer <strong>SGD</strong> giá»‘ng nhÆ° Skip-gram. Trong Ä‘Ã³, á»Ÿ má»—i bÆ°á»›c cá»§a SGD thÃ¬ thá»© ta chá»n ngáº«u nhiÃªn lÃ  má»™t cÃ¢u ngáº¯n trong kho dá»¯ liá»‡u.</p>
<h4 id="trÃ­ch-xuáº¥t-embedding-matrix">TrÃ­ch xuáº¥t embedding matrix</h4>
<p>Sau khi huáº¥n luyá»‡n xong cÃ¡c mÃ´ hÃ¬nh nhÆ° Skip-gram vÃ  CBoW thÃ¬ ta thu Ä‘Æ°á»£c cÃ¡c ma tráº­n trá»ng sá»‘ $\bold{U}$ vÃ  $\bold{V}$. Náº¿u cÃ¡c báº¡n Ä‘á»ƒ Ã½ thÃ¬ trong má»—i mÃ´ hÃ¬nh, thá»© tá»± mÃ¬nh sá»­ dá»¥ng kÃ­ hiá»‡u $\bold{U}$ vÃ  $\bold{V}$ lÃ  khÃ¡c nhau.</p>
<ul>
<li>Trong Skip-gram, $\bold{U}$ lÃ  ma tráº­n trá»ng sá»‘ ná»‘i giá»¯a input-hidden, liÃªn quan Ä‘áº¿n target word vÃ  $\bold{V}$ thÃ¬ ná»‘i giá»¯a hidden-output vÃ  nÃ³ liÃªn quan Ä‘áº¿n context word.</li>
<li>CÅ©ng vÃ¬ sá»± â€œliÃªn quanâ€ giá»¯a ma tráº­n trá»ng sá»‘ lÃ  cÃ¡c tá»«, trong CBoW thÃ¬ $\bold{V}$ Ä‘Æ°á»£c Ä‘Æ°a lÃªn thÃ nh ma tráº­n trá»ng sá»‘ giá»¯a input-hidden, tÆ°Æ¡ng tá»± cho $\bold{U}$.</li>
</ul>
<p>Ta biáº¿t ráº±ng ma tráº­n trá»ng sá»‘ ná»‘i giá»¯a layer input-hidden cÃ³ nhiá»‡m vá»¥ chÃ­nh lÃ  â€œhá»câ€ cÃ¡c Ä‘áº·c trÆ°ng cá»§a tá»« input, cÃ²n ma tráº­n trá»ng sá»‘ ná»‘i giá»¯a hidden-output thÃ¬ cÃ³ nhiá»‡m vá»¥ chÃ­nh lÃ  dá»± Ä‘oÃ¡n tá»«. NhÆ° váº­y, rÃµ rÃ ng lÃ  ta nÃªn dÃ¹ng ma tráº­n trá»ng sá»‘ Ä‘áº§u tiÃªn Ä‘á»ƒ lÃ m embedding matrix. Tuy nhiÃªn, cÃ³ sá»± khÃ¡c biá»‡t nÃ o giá»¯a cÃ¡c ma tráº­n thu Ä‘Æ°á»£c tá»« Skip-gram vÃ  CBoW?</p>
<ul>
<li>Äá»‘i vá»›i Skip-gram, $\bold{U}$ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n target word. Khi Ä‘Ã³, embedding vector cá»§a má»—i tá»« tÃ­nh Ä‘Æ°á»£c dá»±a vÃ o $\bold{U}$ sáº½ mang nhiá»u thÃ´ng tin vá» máº·t <strong>ngá»¯ nghÄ©a</strong> hÆ¡n.</li>
<li>NgÆ°á»£c láº¡i, trong CBoW, $\bold{V}$ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n cÃ¡c context word nÃªn embedding vector cá»§a má»—i tá»« tÃ­nh Ä‘Æ°á»£c sáº½ nghiÃªng vá» phÃ­a <strong>ngá»¯ phÃ¡p</strong>.</li>
</ul>
<p>VÃ­ dá»¥,  vá»›i tá»« â€œcatâ€, ta tÃ­nh embedding vector cá»§a nÃ³ theo cáº£ hai ma tráº­n $\bold{U}$ trong Skip-gram vÃ  $\bold{V}$ trong CBoW. Tiáº¿p Ä‘áº¿n thÃ¬ ta sáº½ tÃ¬m tá»« tÆ°Æ¡ng Ä‘á»“ng vá»›i â€œcatâ€ nháº¥t . Khi Ä‘Ã³, sá»­ dá»¥ng $\bold{U}$ thÃ¬ káº¿t quáº£ cÃ³ thá»ƒ lÃ  â€œdogâ€, cÃ²n dÃ¹ng $\bold{V}$ thÃ¬ ráº¥t cÃ³ thá»ƒ sáº½ lÃ  â€œcatsâ€ ğŸ˜€.</p>
<h4 id="nháº­n-xÃ©t">Nháº­n xÃ©t</h4>
<p>Hai hÆ°á»›ng tiáº¿p cáº­n Skip-gram vÃ  CBoW Ä‘á»u cÃ³ nhá»¯ng Ä‘iá»ƒm máº¡nh vÃ  yáº¿u cá»§a riÃªng nÃ³ (vÃ­ dá»¥ nhÆ° vá» máº·t ngá»¯ nghÄ©a vÃ  ngá»¯ phÃ¡p) nhÆ°ng nhÃ¬n chung thÃ¬ chÃºng Ä‘á»u cho ta nhá»¯ng embedding vector Ä‘á»§ tá»‘t Ä‘á»ƒ sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n khÃ¡c.</p>
<p>Tuy nhiÃªn, ta cÃ³ má»™t Ä‘iá»ƒm yáº¿u khÃ¡ quan trá»ng trong viá»‡c huáº¥n luyá»‡n Skip-gram vÃ  CBoW. Vá» hÃ m loss function thÃ¬ mÃ¬nh Ä‘Ã£ Ä‘á» cáº­p lÃ  chÃºng Ä‘á»u sá»­ dá»¥ng cross-entropy vÃ  cáº§n Ä‘áº¿n $\text{softmax}$ activation function. Trong trÆ°á»ng há»£p tá»« Ä‘iá»ƒn cÃ³ ráº¥t nhiá»u tá»« thÃ¬ thao tÃ¡c tÃ­nh $\text{softmax}$ nÃ y sáº½ ráº¥t ráº¥t lÃ¢u ğŸ˜€</p>
<p>LÄá»ƒ kháº¯c phá»¥c, ta cÃ³ má»™t sá»‘ cÃ¡ch nhÆ° lÃ  sá»­ dá»¥ng <strong>Hierarchy Softmax</strong> hoáº·c lÃ  <strong>Negative Sampling</strong>. Trong bÃ i viáº¿t nÃ y thÃ¬ mÃ¬nh sáº½ khÃ´ng Ä‘á» cáº­p Ä‘áº¿n chÃºng ğŸ˜œ</p>
<h3 id="váº¥n-Ä‘á»-thiÃªn-vá»‹-trong-word-embdding">Váº¥n Ä‘á» thiÃªn vá»‹ trong Word Embdding</h3>
<p>Nghe ráº¥t lÃ  áº£o, nhÆ°ng mÃ  nÃ³ cÃ³ tá»“n táº¡i ğŸ˜… Äiá»u nÃ y xáº£y ra pháº§n lá»›n lÃ  do kho dá»¯ liá»‡u vÄƒn báº£n mÃ  chÃºng ta sá»­ dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng embedding matrix.</p>
<p>Äá»ƒ láº¥y vÃ­ dá»¥, mÃ¬nh sáº½ xÃ©t trÆ°á»ng há»£p liÃªn quan Ä‘áº¿n <strong>giá»›i tÃ­nh</strong>. CÃ¹ng quay láº¡i bÃ i toÃ¡n Analogy Reasoning trong pháº§n <strong>2.2</strong>:</p>
<ul>
<li>Vá»›i 3 tá»« â€œmanâ€, â€œwomanâ€ vÃ  â€œkingâ€ thÃ¬ ta cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c tá»« â€œqueenâ€ sao cho quan há»‡ giá»¯a â€œkingâ€ vÃ  â€œqueenâ€ sáº½ tÆ°Æ¡ng tá»± vá»›i â€œman&quot; vÃ  â€œwomanâ€.</li>
<li>BÃ¢y giá» giáº£ sá»­ ta cÃ³ â€œmanâ€, â€œdoctorâ€, â€œwomanâ€ vÃ  cáº§n tÃ¬m tá»« X sao cho quan há»‡ giá»¯a X vÃ  â€œwomanâ€ tÆ°Æ¡ng tá»± nhÆ° â€œman&quot; vÃ  â€œdoctorâ€. Náº¿u kho dá»¯ liá»‡u liÃªn quan pháº§n lá»›n Ä‘áº¿n viá»‡c ngÆ°á»i Ä‘Ã n Ã´ng lÃ  trá»¥ cá»™t trong gia Ä‘Ã¬nh (xÃ£ há»™i thá»i xa xÆ°a) thÃ¬ káº¿t quáº£ X ráº¥t cÃ³ thá»ƒ lÃ  â€œbabysitterâ€ (ngÆ°á»i trÃ´ng tráº»). NhÆ° váº­y, Ä‘Ã£ cÃ³ váº¥n Ä‘á» thiÃªn vá»‹ (biasing) nam giá»›i.</li>
</ul>
<p>Äá»ƒ háº¡n cháº¿ váº¥n Ä‘á» nÃ y, ta cÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p nhÆ° <strong>Hard Debiasing</strong>, <strong>Soft Debiasing</strong>. MÃ¬nh sáº½ khÃ´ng Ä‘á» cáº­p Ä‘áº¿n nhá»¯ng phÆ°Æ¡ng phÃ¡p nÃ y á»Ÿ Ä‘Ã¢y, cÃ¡c báº¡n cÃ³ thá»ƒ tá»± tÃ¬m Ä‘á»c nhÃ© ğŸ˜€ NÃ³ pháº§n lá»›n lÃ  liÃªn quan Ä‘áº¿n cÃ¡c phÃ©p biáº¿n Ä‘á»•i toÃ¡n há»c.</p>
<p>DÆ°á»›i Ä‘Ã¢y lÃ  minh há»a cho váº¥n Ä‘á» thiÃªn vá»‹ mÃ  mÃ¬nh Ä‘Ã£ láº¥y vÃ­ dá»¥ á»Ÿ trÃªn Ä‘á»ƒ cho cÃ¡c báº¡n dá»… hÃ¬nh dung:</p>
<ul>
<li>Äáº§u tiÃªn, hÆ°á»›ng thay Ä‘á»•i giá»›i tÃ­nh lÃ  tá»« trÃ¡i qua pháº£i. VÃ¬ váº¥n Ä‘á» thiÃªn vá»‹ Ä‘ang xáº£y ra liÃªn quan Ä‘áº¿n giá»›i tÃ­nh nÃªn ta gá»i Ä‘Ã¢y lÃ  <strong>bias direction</strong>.</li>
<li>TrÆ°á»›c khi Ä‘iá»u chá»‰nh, ta tháº¥y embedding vector cá»§a doctor nghiÃªng vá» phÃ­a bÃªn nam giá»›i hÆ¡n, tÆ°Æ¡ng tá»± nhÆ° babysitter.</li>
<li>Sau khi háº¡n cháº¿ váº¥n Ä‘á» thiÃªn vá»‹ Ä‘iá»u chá»‰nh, cÃ¡c embedding vector cá»§a doctor vÃ  baby sitter nÃªn nghiÃªng vá» phÃ­a â€œcÃ´ng báº±ngâ€ hÆ¡n Ä‘á»‘i vá»›i hai giá»›i tÃ­nh, tá»©c lÃ  hÆ°á»›ng <strong>trá»±c giao</strong> vá»›i bias direction.</li>
</ul>
<div>
<div style="display: flex; justify-content: space-around;">
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="height: 300px"  src='./images/biasing.png'>
<p align="center" style="margin: 0; color: #888;">TrÆ°á»›c khi Ä‘iá»u chá»‰nh (embedding vector gá»‘c)</p>
</div>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="height: 300px" src='./images/debiasing.png'>
<p align="center" style="margin: 0; color: #888;">Sau khi thá»±c hiá»‡n debiasing</p>
</div>
</div>
<p align="center">Nguá»“n: <a href='https://vagdevik.wordpress.com/2018/07/08/debiasing-word-embeddings/'>Vagdevik</a></p>
</div>
<h2 id="tÃ i-liá»‡u-tham-kháº£o">TÃ i liá»‡u tham kháº£o</h2>
<ul>
<li><a class="link" href="https://machinelearningcoban.com/tabml_book/ch_embedding/word2vec.html"  target="_blank" rel="noopener"
    >VÅ© Há»¯u Tiá»‡p, Machine Learning cho dá»¯ liá»‡u dáº¡ng báº£ng - Word2vec</a></li>
<li><a class="link" href="https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/"  target="_blank" rel="noopener"
    >Kavita Gane, Word2Vec: A Comparison Between CBOW, SkipGram &amp; SkipGramSI</a></li>
<li><a class="link" href="https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html"  target="_blank" rel="noopener"
    >Dive into Deep Learning, Word2vec</a></li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/embedding/">embedding</a>
        
            <a href="/tags/one-hot-encoding/">one-hot-encoding</a>
        
            <a href="/tags/word2vec/">word2vec</a>
        
            <a href="/tags/skip-gram/">skip-gram</a>
        
            <a href="/tags/cbow/">cbow</a>
        
    </section>


    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/post/rnn/">
        
        

        <div class="article-details">
            <h2 class="article-title">Recurrent Neural Network</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/efficientnet/">
        
        

        <div class="article-details">
            <h2 class="article-title">EfficientNet (2020)</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/mobilenet_v2/">
        
        

        <div class="article-details">
            <h2 class="article-title">MobileNet V2 (2019)</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/densenet/">
        
        

        <div class="article-details">
            <h2 class="article-title">DenseNet (2018)</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/cam/">
        
        

        <div class="article-details">
            <h2 class="article-title">CAM, Grad-CAM vÃ  Score-CAM trong CNN</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

<div id="disqus_thread"></div>

<p><b>LÆ°u Ã½.</b> Náº¿u pháº§n Comment khÃ´ng load ra Ä‘Æ°á»£c thÃ¬ cÃ¡c báº¡n vÃ o DNS setting cá»§a Wifi/LAN vÃ  Ä‘á»•i thÃ nh "8.8.8.8" nhÃ© (server cá»§a Google)!</p>


<script>
    

    

    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://htrvu-blog.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2023 Hoang Trong Vu
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
