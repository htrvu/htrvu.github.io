<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Giới thiệu về bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU trong đánh giá mô hình Machine Translation'>
<title>Bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU</title>

<link rel='canonical' href='https://htrvu.github.io/post/mt_seq2seq/'>

<link rel="stylesheet" href="/scss/style.min.5eda91a11f055cbfcec5ec0fd36a1f7cba21a6a47d4778547d7d8f3099d2ebe2.css"><meta property='og:title' content='Bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU'>
<meta property='og:description' content='Giới thiệu về bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU trong đánh giá mô hình Machine Translation'>
<meta property='og:url' content='https://htrvu.github.io/post/mt_seq2seq/'>
<meta property='og:site_name' content='Trong-Vu Hoang'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='rnn' /><meta property='article:tag' content='lstm' /><meta property='article:tag' content='gru' /><meta property='article:tag' content='seq2seq' /><meta property='article:tag' content='machine translation' /><meta property='article:tag' content='bleu' /><meta property='article:published_time' content='2023-03-19T00:25:41&#43;07:00'/><meta property='article:modified_time' content='2023-03-19T00:25:41&#43;07:00'/>
<meta name="twitter:title" content="Bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU">
<meta name="twitter:description" content="Giới thiệu về bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU trong đánh giá mô hình Machine Translation">
    <link rel="shortcut icon" href="/neural.png" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu4ef57fa6d8ae56d86d9663ef18f7ace5_124758_300x0_resize_q75_box.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Trong-Vu Hoang</a></h1>
            <h2 class="site-description">On my way!</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/htrvu'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://www.linkedin.com/in/htrvu/'
                        target="_blank"
                        title="Linkedin"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"> <path stroke="none" d="M0 0h24v24H0z" fill="none"/> <rect x="4" y="4" width="16" height="16" rx="2" /> <line x1="8" y1="11" x2="8" y2="16" /> <line x1="8" y1="8" x2="8" y2="8.01" /> <line x1="12" y1="16" x2="12" y2="11" /> <path d="M16 16v-3a2 2 0 0 0 -4 0" /> </svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/about/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#bài-toán-machine-translation">Bài toán Machine Translation</a>
      <ol>
        <li><a href="#giới-thiệu">Giới thiệu</a></li>
        <li><a href="#rule-based-machine-translation">Rule-based Machine Translation</a></li>
        <li><a href="#statistical-machine-translation">Statistical Machine Translation</a></li>
        <li><a href="#neural-machine-translation">Neural Machine Translation</a></li>
      </ol>
    </li>
    <li><a href="#mô-hình-sequence-to-sequence">Mô hình Sequence to Sequence</a>
      <ol>
        <li><a href="#seq2seq-đơn-giản">Seq2seq đơn giản</a></li>
        <li><a href="#deep-seq2seq">Deep Seq2seq</a></li>
        <li><a href="#kỹ-thuật-teacher-forcing-và-đảo-ngược-câu-input">Kỹ thuật Teacher Forcing và đảo ngược câu input</a></li>
        <li><a href="#các-ứng-dụng-khác-của-seq2seq">Các ứng dụng khác của Seq2seq</a></li>
      </ol>
    </li>
    <li><a href="#độ-đo-bleu">Độ đo BLEU</a></li>
    <li><a href="#tài-liệu-tham-khảo">Tài liệu tham khảo</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/nlp/" style="background-color: #2a9d8f; color: #fff;">
                Natual Language Processing
            </a>
        
            <a href="/categories/dl/" style="background-color: #2a9d8f; color: #fff;">
                Deep Learning
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/mt_seq2seq/">Bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Giới thiệu về bài toán Machine Translation, mô hình Sequence to Sequence và độ đo BLEU trong đánh giá mô hình Machine Translation
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Mar 19, 2023</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    12 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h2 id="bài-toán-machine-translation">Bài toán Machine Translation</h2>
<h3 id="giới-thiệu">Giới thiệu</h3>
<p><strong>Machine Translation</strong> (dịch máy) là bài toán rất phổ biến trong lĩnh vực NLP. Sản phẩm Google Dịch mà chúng ta vẫn dùng hằng ngày chính là một mô hình dịch máy <strong>khá tốt</strong> và nó được huấn luyện bởi Google 😀</p>
<p style="display: flex; flex-direction: column; align-items: center;">
<img style="max-width: 100%;" src='./images/gg_translate.png'>
</p>
<p>Thật ra bài toán Machine Translation đã ra đời từ rất lâu. Tất nhiên rồi, vì nó đóng vai trò rất quan trọng trong giao tiếp. Kể từ khi Statistical Machine Learning (máy học thống kê) rồi cho đến Deep Learning phát triển mạnh thì dần càng có nhiều nghiên cứu về Machine Translation được thực hiện và độ chính xác của các mô hình đã được cải thiện một cách đáng kể.</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 400px;" src='./images/mt_history.png'>
<p align="center" style="margin: 0; color: #888;">
Nguồn: <a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/">FreeCodeCamp</a>
</p>
</div>
<h3 id="rule-based-machine-translation">Rule-based Machine Translation</h3>
<p>Ban đầu, Machine Translation được giải quyết bằng cách dựa vào những cách như dịch trực tiếp từng từ một dựa vào từ điển, sau đó là dịch từng cụm, chuyển từ các từ hay cụm từ thành một dạng biểu diễn trung gian (ví dụ như ảnh), rồi từ đó tính ra từ của ngôn ngữ khác. Những phương pháp này gọi chung là <strong>Rule-based Machine Translation.</strong> Tất nhiên là dịch như vậy thì độ chính xác sẽ khó mà cao được rồi 😀</p>
<div>
<div style="display: flex; justify-content: space-around; align-items: center;">
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="height: 150px"  src='./images/rule-based_1.png'>
</div>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="height: 200px" src='./images/rule-based_2.png'>
</div>
</div>
<p align="center">Minh họa cho Rule-based Machine Translation<br>Nguồn: <a href='https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5'>FreeCodeCamp</a>
</div>
<h3 id="statistical-machine-translation">Statistical Machine Translation</h3>
<p>Với Statistical Machine Translation (SMT), người ta xây dựng khá nhiều các phương pháp dựa trên cơ sở là các mô hình thống kê. Ta có thể kể ra một vài phương pháp như <strong>Word-based</strong> (bag-of-words, word-alignment), <strong>Phase-based</strong>, <strong>Syntax-based</strong>.</p>
<p>Lấy ví dụ với bài toán dịch Tiếng Anh sang Tiếng Việt. Với câu input Tiếng Anh là $x$, ta sẽ tìm câu Tiếng Việt $y_0$ sao cho xác suất $y_0$ là câu dịch của $x$ là cao nhất:</p>
<p>$$
y_0 = \argmax_{y} P(y|x)
$$</p>
<p>Sử dụng quy tắc Bayes, ta có</p>
<p>$$
P(y|x)= P(x|y) P(y)
$$</p>
<p>Do đó, trong mô hình SMT, ta sẽ có sự góp mặt của hai thành phần: <strong>Translation Model</strong> (cho $P(x|y)$) và <strong>Language Model</strong> (cho $P(y)$)</p>
<ul>
<li><strong>Translation Model (TM)</strong> liên quan đến việc dịch các từ và cụm từ giữa hai ngôn ngữ (<strong>fidelity</strong> - sự chính xác trong dịch thuật). Để huấn luyện TM thì ta cần sử dụng tập dữ liệu “song ngữ”, tức là tập các cặp câu Anh-Việt tương ứng. Kỹ thuật thường được dùng trong huấn luyện TM là word alignment. Mình sẽ không đề cập đến nó ở trong bài viết này 😀</li>
<li><strong>Language Model (LM)</strong> sẽ tập trung vào sự trôi chảy của câu được dịch ra (<strong>fluency</strong>). Để huấn luyện LM thì ta chỉ cần dùng tập dữ liệu đơn ngữ. Có thể kể đến một số cách huấn luyện cơ bản như là Mô hình Markov (thuần túy dựa vào xác suất và thống kê), hoặc là về sau thì có thêm Recurrent Neural Network.</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 200px;" src='./images/tm_lm.png'>
<p align="center" style="margin: 0; color: #888;">Translation Malde và Language Model<br>
Nguồn: VietAI
</p>
</div>
<p>Để sử dụng mô hình SMT trong thực tế, tất nhiên là ta không thể đi thử toàn bộ câu output $y$ để tính xác suất rồi so sánh được. Ta sẽ sử dung một thuật toán <strong>heuristic search</strong> để tìm ra câu dịch phù hợp.</p>
<p>Cho đến trước năm 2016 thì Google Dịch vẫn sử dụng mô hình SMT, trước khi nó chuyển hoàn toàn sang Neural Machine Translation (phần kế tiếp). Ta có thể liệt kê một số hạn chế của SMT như sau:</p>
<ul>
<li>Hệ thống thật sự sẽ rất phức tạp với nhiều thành phần tách rời nhau</li>
<li>Cần thực hiện quá trình feature engineering rất nhiều để có thể nắm bắt được đặc trưng của từng ngôn ngữ</li>
<li>Chi phí duy trì và phát triển rất tốn kém.</li>
</ul>
<h3 id="neural-machine-translation">Neural Machine Translation</h3>
<p>Khi Deep Learning dần phát triển mạnh, ta có nhiều mô hình được xây dựng để giải quyết bài toán Machine Translation. Chúng được gọi chung là <strong>Neural Machine Translation (NMT)</strong></p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 200px;" src='./images/tm_lm.png'>
<p align="center" style="margin: 0; color: #888;">Minh họa cho các mô hình trong nhóm Neural Machine Translation<br>
Nguồn: <a href='https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/'>FreeCodeCamp</a>
</p>
</div>
<p>Mục đích của Machine Translation là ta đi dịch một văn bản từ ngôn ngữ X sang ngôn ngữ Y, tức là input của bài toán này là một chuỗi và output cũng là một chuỗi. Và với các bài toán có dữ liệu dạng chuỗi thì ta thường nghĩ ngay đến Recurrent Neural Network!</p>
<p>Loại mô hình RNN thường được sử dụng trong bài toán này là <strong>many-to-many</strong>. Trong bài viết về <a class="link" href="https://htrvu.github.io/post/rnn/" >RNN</a>, mình có đề cập đến hai dạng khác nhau của mô hình many-to-many như sau:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 300px;" src='./images/many-to-many.png'>
</div>
<ul>
<li>Xét dạng mô hình many-to-many phía bên phải. Ta thấy rằng nó đang hoạt động theo kiểu như <strong>dịch dần từng chữ một</strong>, và có vẻ đây không phải là cách mà con người sử dụng để dịch văn bản 😀</li>
<li>Đối với phía bên trái, mô hình hoạt động theo hướng là <strong>đọc hiểu toàn bộ input</strong> rồi sau đó mới bắt đầu dịch. Nghe rất hợp lý! Dạng kiến trúc này thường được gọi là <strong>Encoder-Decoder</strong>, trong đó:
<ul>
<li><strong>Encoder</strong> sẽ rút trích các đặc trưng ở trong câu input. Sau khi hoàn thành, nó sẽ chuyển thông tin này cho decoder.</li>
<li><strong>Decoder</strong> là một Language Model sinh ra các từ cho câu output, dựa trên các từ đã sinh trước đó và lượng thông tin đến từ encoder.</li>
</ul>
</li>
</ul>
<p>Nếu mô tả ngắn gọn thì ta sẽ có sơ đồ như sau:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 200px;" src='./images/enc_dec_simple.png'>
<p align="center" style="margin: 0; color: #888;">Sơ đồ của kiến trúc Encoder-Decoder<br>
Nguồn: <a href='http://d2l.ai/chapter_recurrent-modern/encoder-decoder.html'>Dive into DL</a>
</p>
</div>
<p>Cụ thể hơn một chút với dạng mô hình <strong>RNN Encoder-Decoder</strong>, “thông tin” mà encoder gửi cho decoder chính là hidden state của giai đoạn cuối cùng trong encoder.</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 300px;" src='./images/enc_dec_ex.png'>
<p align="center" style="margin: 0; color: #888;">Minh họa mô hình RNN Encoder-Decoder<br>
Nguồn: VietAI
</p>
</div>
<p>Ta cũng có thể xem NMT như là một SMT với khả năng tính toán trực tiếp xác suất $P(y|x)$:</p>
<p>$$
P(y|x) = P(y_1|x) \times P(y_2|y_1, x) \times \cdots P(y_T | y_{T -1}, \cdots, y_1, x)
$$</p>
<p>So với SMT, NMT có một số điểm mạnh hơn như sau:</p>
<ul>
<li>Hiệu năng tốt hơn: Dịch chính xác, trôi chảy hơn và câu văn đa dạng hơn</li>
<li>Dễ tối ưu mô hình hơn (huấn luyện end-to-end)</li>
<li>Con người không cần phải can thiệp quá nhiều vào thao tác feature engineering</li>
</ul>
<p>Bên cạnh đó, NMT cũng có một hạn chế quan trọng là mô hình này khó để “có thể giải thích được”, các hoạt động bên traong như là một blackbox (xem thêm bài viết về XAI tại đây).</p>
<h2 id="mô-hình-sequence-to-sequence">Mô hình Sequence to Sequence</h2>
<p><strong>Sequence to Sequence (seq2seq)</strong> là mô hình dịch máy có kiến trúc dạng Encoder-Decoder. Nó được các nhà nghiên cứu tại Google nghiên cứu và công bố vào năm 2016, cũng là năm mà Google Dịch chuyển từ SMT sang NMT 😀</p>
<h3 id="seq2seq-đơn-giản">Seq2seq đơn giản</h3>
<p>Ở phiên bản đơn giản nhất của seq2seq, kiến trúc mô hình sẽ giống với hình minh họa của Encoder-Decoder ở trên. Trong đó, ta có sử dụng embedding layer và các cell có thể là RNN cell, LSTM cell hoặc GRU cell (xem thêm bài viết về LSTM và GRU tại <a class="link" href="https://htrvu.github.io/post/lstm-gru/" >đây</a>). Ta có thể mô tả kiến trúc này như hình bên dưới:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 330px;" src='./images/seq2seq_simple.png'>
<p align="center" style="margin: 0; color: #888;">Kiến trúc Seq2seq đơn giản<br>
Nguồn: VietAI
</p>
</div>
<ul>
<li><strong>Lưu ý.</strong> Trong Seq2seq, ta hoàn toàn có thể dùng <a class="link" href="https://htrvu.github.io/post/deep-rnn_birnn/" >Bidirectional RNN</a>. Khi đó, lượng “thông tin”, hay là trạng thái <strong>S</strong> mà encoder gửi cho decoder có thể được tính bằng trung bình của trạng thái cuối cùng của mỗi hướng truyền.</li>
</ul>
<p>Nếu xét về mặt công thức của Encoder và Decoder thì nó sẽ giống với trong RNN thông thường. Chỉ đặc biệt ở một phần là thời điểm đầu tiên của Decoder sẽ có trạng thái ẩn truyền vào là khác 0 (nhận được từ Encoder).</p>
<h3 id="deep-seq2seq">Deep Seq2seq</h3>
<p>Từ RNN, ta có <a class="link" href="https://htrvu.github.io/post/deep-rnn_birnn/" >Deep RNN</a>. Vậy thì với Seq2seq cũng như thế 😀 Deep Seq2seq là dạng kiến trúc mà Encoder và Decoder có nhiều recurrent layer liên tiếp nhau. Khi đó, số lượng trạng thái mà Encoder truyền qua Decoder cũng sẽ nhiều lên. Ví dụ như sau:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 400px;" src='./images/deep_seq2seq.png'>
<p align="center" style="margin: 0; color: #888;">Minh họa kiến trúc Deep Seq2seq<br>
Nguồn: VietAI
</p>
</div>
<p>Để ý rằng, recurrent layer thứ $i$ trong Decoder sẽ nhận trạng thái đầu từ recurrent layer tương ứng của Encoder.</p>
<p>Chỉ bằng cách đơn giản là chồng thêm nhiều recurrent layer trong kiến trúc mô hình, Deep Seq2seq đã đạt độ hiệu quả rất vượt trội 😀</p>
<h3 id="kỹ-thuật-teacher-forcing-và-đảo-ngược-câu-input">Kỹ thuật Teacher Forcing và đảo ngược câu input</h3>
<p>Đầu tiên, ta thấy rằng để huấn luyện được một mô hình Seq2seq thì ta cần có input cho cả 2 thành phần là Encoder và Decoder. Với Encoder thì chắc chắn input chính là đoạn văn bản cần dịch. Còn Decoder thì sao?</p>
<p>Input của Decoder được tạo ra bằng một kỹ thuật gọi là <strong>Teacher Forcing</strong>. Ví dụ, câu văn bản input là “Hôm nay tôi đi học” và label của nó là “Today I go to school”. Khi đó, input và label của Decoder sẽ là:</p>
<ul>
<li>Input: “Today I go to”</li>
<li>Label: “I go to school”</li>
</ul>
<p>Nhìn vào thì ta sẽ thấy ngay ý tưởng của Teacher Forcing 😀</p>
<ul>
<li>Đối với quá trình dịch (hay là dự đoán) thì Decoder hoạt động giống với mô hình RNN thông thường: Sử dụng output của thời điểm liền trước để làm input cho thời điểm hiện tại</li>
</ul>
<p>Bên cạnh Teacher Forcing, các tác giả của Seq2seq còn sử dụng một kỹ thuật để giúp Seq2seq đạt được một hiệu năng ấn tượng là <strong>đảo ngược câu input</strong> (label thì giữ nguyên). Nghe rất ảo nhưng… it works! Ví dụ:</p>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 350px;" src='./images/input_reverse.png'>
<p align="center" style="margin: 0; color: #888;">Minh họa kỹ thuật đảo ngược câu input trong Seq2seq<br>
Nguồn: VietAI
</p>
</div>
<p>Dù không đưa ra được lời giải thích chặt chẽ là vì sao kỹ thuật này lại mang đến kết quả rất tốt nhưng các tác giả của Seq2seq cũng có nêu ra một số lí do thiên về phần trực giác. Lí do chính là vì nhờ cách làm này mà mô hình có thể học được thêm các mối quan hệ phụ thuộc giữa các từ trong câu input và label.</p>
<ul>
<li>Khi ta “dịch xuôi”, với những input có độ dài lớn thì sau khi Encoder tính toán xong, đến với Decoder thì Decoder đang đi dịch cho một từ cách thời điểm hiện tại một khoảng cách rất xa, và với các từ sau cũng vậy (khoảng cách của từng cặp là xấp xỉ nhau).</li>
<li>Trong khi đó, nếu đảo ngược input thì trung bình khoảng cách những cặp từ sẽ gần như không đổi nhưng sẽ có những cặp ở rất gần nhau. Từ đó nó góp phần làm giảm hiện tượng vanishing gradient (hay còn gọi tên khác là time lag mà các tác giả sử dụng trong paper).</li>
</ul>
<h3 id="các-ứng-dụng-khác-của-seq2seq">Các ứng dụng khác của Seq2seq</h3>
<p>Dù được phát triển cho bài toán Machine Translation được Seq2seq có thể được áp dụng vào rất nhiều bài toán khác nhau, và chúng đều là các bài toán rất thú vị và liên quan đến nhiều mảng khác nhau trong Deep Learning. Trong đó có hai bài toán nổi bật là <strong>Image Captioning</strong> và <strong>Speech Recognition</strong>.</p>
<p>Nhìn vào kiến trúc của Seq2seq thì ta có nhận xét rằng nếu Encoder đủ tốt để rút trích các đặc trưng từ input và truyền vào cho Decoder thì Decoder có thể làm rất nhiều điều.</p>
<ul>
<li>Đối với <strong>Image Captioning</strong>, Encoder sẽ rút trích đặc trưng của ảnh và truyền vector này vào Decoder là ta đã có khả năng sinh ra câu mô tả cho tấm ảnh đó</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 350px;" src='./images/image_captioning.png'>
<p align="center" style="margin: 0; color: #888;">Image Captioning sử dụng ý tưởng Seq2seq<br>
Nguồn: <a href='https://www.analyticsvidhya.com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/'>Analytics Vidhya</a>
</p>
</div>
<ul>
<li><strong>Speech Recognition</strong> là bài toán sinh ra đoạn văn bản được nói lên trong file âm thanh. Như vậy, chỉ cần một Encoder rút trích được đặc trưng của âm thanh rồi truyền vào Decoder là ta đã có thể có một giải pháp cho bài toán này.</li>
</ul>
<div style="display: flex; flex-direction: column; align-items: center;">
<img style="max-height: 350px;" src='./images/speech_recognition.png'>
<p align="center" style="margin: 0; color: #888;">Speech Recognition sử dụng ý tưởng Seq2seq<br>
Nguồn: <a href='https://www.researchgate.net/figure/Sequence-to-sequence-Autoencoder-SA-consists-of-two-RNNs-RNN-Encoder-the-left-large_fig4_307889408'>Research Gate</a>
</p>
</div>
<h2 id="độ-đo-bleu">Độ đo BLEU</h2>
<p>Để biết được một mô hình Machine Translation có hoạt động đủ tốt hay không thì ta cần có một độ đo. <strong>BLEU (Bilingual Evaluation Understudy)</strong> chính là một trong những độ đo cơ bản và phổ biến nhất.</p>
<p>BLEU sẽ đánh giá một câu dịch dựa theo các <strong>n-grams</strong> của câu đó với các câu label có trong tập dữ liệu. Ví dụ:</p>
<ul>
<li>
<p>Câu input là $x$ = “Con mèo nằm ở trên bàn”</p>
<p>Output của mô hình là $\hat{y}$ = “The cat on table”</p>
<ul>
<li>1-grams (hay là unigrams): The, cat, on, table</li>
<li>2-grams (bigrams): The cat, cat on, on table</li>
<li>Tương tự với các giá trị n khác</li>
</ul>
</li>
<li>
<p>Giả sử input $x$ có hai câu label trong tập dữ liệu:</p>
<ul>
<li>$o_1$ = “The cat is on a table”</li>
<li>$o_2$ = “The cat lies on a desk”</li>
</ul>
</li>
</ul>
<p>Đặt $N_0$ là tập các $n_0$-grams của câu output $\hat{y}$. Khi đó, giá trị điểm BLEU (hay là BLEU score) của $\hat{y}$ <strong>tính theo $n_0$-grams</strong> là</p>
<p>$$
s_n = \frac{\sum_{n_0\text{-gram} \in N_0} \text{count}_{\text{clip}}(n_0\text{-gram})}{\sum_{n_0\text{-gram} \in N_0} \text{count}(n_0\text{-gram})}
$$</p>
<p>trong đó:</p>
<ul>
<li>Tử số được tính theo các câu label của input $x$, với $\text{count}_{\text{clip}} (n_0\text{-gram})$ là số lần xuất hiện lớn nhất của gram này ở trong các câu label.
<ul>
<li>Với ví dụ trên, ta có hai câu label là $o_1$ và $o_2$. Giả sử xét một 2-gram “The cat” thì gram này đều xuất hiện 1 lần ở trong mỗi câu label nên giá trị $\text{count}_\text{clip}$ của nó là 1.</li>
</ul>
</li>
<li>Mẫu số được tính tại chính câu output $\hat{y}$, với $\text{count}(n_0\text{-gram})$ là số lần xuất hiện của gram này ở trong câu output.</li>
</ul>
<p>Như vậy, tất nhiên là $s_n \leq 1$ và $s_n$ càng lớn thì câu output $\hat{y}$ càng “gần” với các câu label trong tập dữ liệu.</p>
<p>Để tính được <strong>điểm BLEU thật sự c</strong>ủa câu $\hat{y}$, ta sẽ tính $s_n$ với một số giá trị $n$ và sau đó tính trung bình theo một công thức khá đặc biệt:</p>
<p>$$
BLEU(\hat{y}) = BP \times \exp \left ( \frac{1}{m} \sum_{n=1}^m s_n \right )
$$</p>
<p>trong đó $BP$ là BLEU penalties, với ý nghĩa là nếu mô hình cho ra những câu output <strong>quá ngắn</strong> (ngắn hơn các câu trong tập dữ liệu) thì sẽ bị phạt (giảm điểm BLEU):</p>
<p>$$
\begin{aligned}
BP = \left\{\begin{matrix}
1, &amp; \text{if } len(\hat{y}) &gt; \min(len(o_i)) \\
\exp \left ( 1 - \frac{\min(len(o_i))}{len(\hat{y})} \right ), &amp; \text{otherwise}
\end{matrix}\right.
\end{aligned}
$$</p>
<p><strong>Vì sao cần phải có BLEU penalties?</strong></p>
<ul>
<li>Để ý rằng, nếu mô hình chỉ cho ra một câu output chứa đúng một gram luôn xuất hiện trong các câu label thì ta luôn có $s_n = 1$ 😀 Nếu không phạt thì hỏng!</li>
</ul>
<h2 id="tài-liệu-tham-khảo">Tài liệu tham khảo</h2>
<ul>
<li><a class="link" href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/"  target="_blank" rel="noopener"
    >FreeCodeCamp, A history of machine translation from the Cold War to deep learning</a></li>
<li><a class="link" href="http://d2l.ai/chapter_recurrent-modern/seq2seq.html"  target="_blank" rel="noopener"
    >Dive into Deep Learning, Encoder-Decoder Seq2Seq for Machine Translation</a></li>
<li>VietAI, Deep Learning Foundation Course 2019, Lecture 14 - Machine Translation and Sequence to Sequence model</li>
<li><a class="link" href="https://www.coursera.org/learn/nlp-sequence-models?specialization=deep-learning"  target="_blank" rel="noopener"
    >DeepLearning.AI, Deep Learning Specialization, 5. Sequence Models</a></li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/rnn/">rnn</a>
        
            <a href="/tags/lstm/">lstm</a>
        
            <a href="/tags/gru/">gru</a>
        
            <a href="/tags/seq2seq/">seq2seq</a>
        
            <a href="/tags/machine-translation/">machine translation</a>
        
            <a href="/tags/bleu/">bleu</a>
        
    </section>


    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css"integrity="sha256-J&#43;iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s="crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js"integrity="sha256-InsNdER1b2xUewP&#43;pKCUJpkhiqwHgqiPXDlIk7GzBu4="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js"integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI="crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">Related content</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/post/deep-rnn_birnn/">
        
        

        <div class="article-details">
            <h2 class="article-title">Deep RNN và Bidirectional RNN</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/lstm-gru/">
        
        

        <div class="article-details">
            <h2 class="article-title">Long Short-Term Memory (LSTM) và Gated Recurrent Unit (GRU)</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/rnn/">
        
        

        <div class="article-details">
            <h2 class="article-title">Recurrent Neural Network (RNN)</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/transformer_01/">
        
        

        <div class="article-details">
            <h2 class="article-title">Cơ chế Attention và mô hình Transformer</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/post/word-embedding/">
        
        

        <div class="article-details">
            <h2 class="article-title">Word Embedding</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

<div id="disqus_thread"></div>

<p><b>Lưu ý.</b> Nếu phần Comment không load ra được thì các bạn vào DNS setting của Wifi/LAN và đổi thành "8.8.8.8" nhé (server của Google)!</p>


<script>
    

    

    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://htrvu-blog.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2023 Trong-Vu Hoang
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.16.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
